{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2279c7de-30f4-4ae6-9f40-a1e84365c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import brier_score_loss, accuracy_score\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from skqreg.estimators import QuantisticRegression\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from bisect import bisect_left\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "208b9960-739a-49d6-a7d1-2aaa38779d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheid/.cache/pypoetry/virtualenvs/scikit-quantistic-regresion-tuRLV2Fq-py3.11/lib/python3.11/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = fetch_openml(data_id=43979, return_X_y=True, as_frame=False)\n",
    "y = np.array(y == \"True\", dtype=int)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e9d2cae-af83-4b83-92fd-e84be958efb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8071629349617137"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=500).fit(X,y)\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c016d886-a90b-4b48-92bf-ad9c46bfe47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, -1, 5, 0, -1, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(s):\n",
    "    c = clf.coef_\n",
    "    c = c/np.abs(c).sum()*10*s\n",
    "    return np.abs(np.abs(c.round()).sum() - 10)\n",
    "\n",
    "x = minimize(f, x0=1, method=\"Nelder-Mead\", options=dict(initial_simplex=[[.8],[1.2]], fatol=.9)).x.item()\n",
    "\n",
    "c = clf.coef_\n",
    "c = c/np.abs(c).sum()*10*x\n",
    "n_cuts = c.round().astype(int).squeeze().tolist()\n",
    "n_cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0f08b9-bc4b-497b-87c6-a653613faee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.33333333,  0.7012987 ,  0.70588235,  0.82191781,  0.82222222,\n",
       "         0.875     ,  0.87573964,  0.92971246,  0.92977528,  0.92978723,\n",
       "        34.06666667]),\n",
       " array([0.33333333, 0.33333333, 0.36231884, 0.36231884, 0.46456693,\n",
       "        0.46456693, 0.49484536, 0.49484536, 0.5       , 0.50108438,\n",
       "        0.50108438]),\n",
       " array([0.16666667, 0.33333333, 0.5       , 0.66666667, 0.83333333]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso = IsotonicRegression().fit(X[:,3],y)\n",
    "iso.X_thresholds_,iso.y_thresholds_,np.linspace(0,1,num=5+2)[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "759c6ece-860f-4224-9cbd-5ba3d4f8d9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2.5658],\n",
       " [0, 1, 3.8365],\n",
       " [0, 1, 5.0016],\n",
       " [2, -1, 5.853300733496333],\n",
       " [3, 1, 0.3333333333333333],\n",
       " [3, 1, 0.3333333333333333],\n",
       " [3, 1, 0.9297752808988764],\n",
       " [3, 1, 34.06666666666667],\n",
       " [3, 1, 34.06666666666667],\n",
       " [5, -1, 1.3186003683241252]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuts = []\n",
    "for i,c in enumerate(n_cuts):\n",
    "    if c == 0:\n",
    "        continue\n",
    "    iso = IsotonicRegression().fit(X[:,i],y)\n",
    "    for split in np.linspace(0,1,num=abs(c)+2)[1:-1]:\n",
    "        cuts.append([i,1 if c >=0 else -1, iso.X_thresholds_[min(bisect_left(iso.y_thresholds_, split),len(iso.X_thresholds_)-1)]] )\n",
    "cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f370d7f-ba42-4564-bfd6-3be9f831fa5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2053794707763885, 0.6777648541242609)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for f, sgn, cut in cuts:\n",
    "    results.append(X[:,f] * sgn >= cut)\n",
    "results = np.array(results, dtype=int)\n",
    "ypred = results.sum(axis=0)/10\n",
    "brier_score_loss(y,ypred), accuracy_score(y,ypred>.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
